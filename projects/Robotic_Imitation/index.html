---
layout: default
title: "Learning Agile Robotic Locomotion Skills by Imitating Animals"
---

<center><h1>{{ page.title }}</h1></center>

<td>
	<center>
		arXiv Preprint 2020<br>
		<br>
		<nobr>Xue Bin Peng (1,2)</nobr> &emsp;&emsp; <nobr>Erwin Coumans (1)</nobr> &emsp;&emsp; <nobr>Tingnan Zhang (1)</nobr> &emsp;&emsp; <nobr>Tsang-Wei Edward Lee (1)</nobr> &emsp;&emsp; <nobr>Jie Tan (1)</nobr> &emsp;&emsp; <nobr>Sergey Levine (1,2)</nobr><br>
		<br>
		<nobr>(1) Google Research</nobr> &emsp;&emsp; <nobr> (2) University of California, Berkeley </nobr><br>
		<br>
		<img style="vertical-align:middle" src="robotic_imitation_teaser.png"  width="100%" height="inherit"/>		
	</center>
</td>

<br>
	
<td>
	<hr>
	<h3 style="margin-bottom:10px;">Abstract</h3>
	Reproducing the diverse and agile locomotion skills of animals has been a longstanding
	challenge in robotics. While manually-designed controllers have been able to emulate
	many complex behaviors, building such controllers involves a time-consuming and
	difficult development process, often requiring substantial  expertise of the nuances
	of each skill. Reinforcement learning provides an appealing alternative for automating
	the manual effort involved in the development of controllers. However, designing
	learning objectives that elicit the desired behaviors from an agent can also require a
	great deal of skill-specific expertise. In this work, we present an imitation learning
	system that enables legged robots to learn agile locomotion skills by imitating
	real-world animals. We show that by leveraging reference motion data, a single
	learning-based approach is able to automatically synthesize controllers for a diverse
	repertoire behaviors for legged robots. By incorporating sample efficient domain
	adaptation techniques into the training process, our system is able to learn adaptive
	policies in simulation that can then be quickly adapted for real-world deployment. To
	demonstrate the effectiveness of our system, we train an 18-DoF quadruped robot to
	perform a variety of agile behaviors ranging from different locomotion gaits to
	dynamic hops and turns.
</td>

<td>
	<h3> Paper: [<a href="2020_Robotic_Imitation.pdf">PDF</a>] &nbsp; &nbsp; &nbsp; Code: [<a href="https://github.com/google-research/motion_imitation">GitHub</a>] &nbsp; &nbsp; &nbsp; Blog: [<a href="https://ai.googleblog.com/2020/04/exploring-nature-inspired-robot-agility.html">Google</a> / <a href="https://bair.berkeley.edu/blog/2020/04/03/laikago/">BAIR</a>] &nbsp; &nbsp; &nbsp; Preprint: [<a href="http://arxiv.org/abs/2004.00784">arXiv</a>] </h3>
</td>

<tr>
		<h3 style="margin-bottom:10px;">Video</h3>
		<iframe width="560" height="315" src="https://www.youtube.com/embed/lKYh6uuCwRY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</tr>
	
<br>
<br>

<h3 style="margin-bottom:0px;">Bibtex</h3>
<pre>
@misc{
    RoboImitationPeng20,
    title={Learning Agile Robotic Locomotion Skills by Imitating Animals},
    author={Xue Bin Peng and Erwin Coumans and Tingnan Zhang and Tsang-Wei Lee and Jie Tan and Sergey Levine},
    year={2020},
    eprint={2004.00784},
    archivePrefix={arXiv},
    primaryClass={cs.RO}
}
</pre>
